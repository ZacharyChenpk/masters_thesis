{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualising the database using iGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import sklearn.preprocessing\n",
    "import sklearn.decomposition\n",
    "import sklearn.model_selection\n",
    "import sklearn.cluster\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import py2neo\n",
    "import seaborn as sb ##includes convenient heatmaps and boxplots\n",
    "import scipy as sp\n",
    "import pylab as pl\n",
    "import igraph\n",
    "#import cairocffi as cairo\n",
    "import cairo\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_database(query):\n",
    "    # REMEMBER TO BE CONNECTED TO IMPERIAL WIFI!\n",
    "    graph_db = py2neo.Graph(\"https://dsi-bitcoin.doc.ic.ac.uk:7473/db/data/\", auth=(\"adi\", \"aditi123\"))\n",
    "    return graph_db.run(query)\n",
    "\n",
    "def get_block_data(first_block, last_block):\n",
    "    query_string = \"\"\"\n",
    "                    MATCH (b:Block) <-[:MINED_IN]- (t:Tx) <-[:IN]- (txi:TxIn) <-[:UNLOCK]- (iadr:Address)\n",
    "                    WHERE b.height >= {} AND b.height <= {}\n",
    "                    MATCH (txi) <-[:SPENT]- (txo_in:TxOut) \n",
    "                    MATCH (oadr:Address) <-[:LOCK]- (txo_out:TxOut) <-[:OUT]- (t) \n",
    "                    \n",
    "                    RETURN iadr.address as iadr, oadr.address as oadr, txo_in.value as input_val, txo_out.value as output_val, ID(txo_in) as id_txo_in, ID(txi) as id_txi, ID(t) as id_t, ID(txo_out) as id_txo_out\n",
    "                    \n",
    "                    \"\"\".format(first_block, last_block)\n",
    "    return query_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = query_database(get_block_data(400000,400000))\n",
    "df = result.to_data_frame()\n",
    "#df = pd.read_csv('./csv/400000addr.csv')\n",
    "#df[[col for col in df.columns if not 'Unnamed' in col]]\n",
    "\n",
    "# New columns for number of input and output transaction ids\n",
    "df['num_txo'] = df.groupby('id_t')['id_txo_out'].transform('nunique')\n",
    "df['num_txi'] = df.groupby('id_t')['id_txi'].transform('nunique')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding users by using heuristic measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heuristic 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "#CHANGE LATER TO QUERY DATABASE INSTEAD\n",
    "def iadrs_from_tx(id_t):\n",
    "    return set(df['iadr'][df[\"id_t\"] == id_t])\n",
    "\n",
    "def oadrs_from_tx(id_t):\n",
    "    return set(df['oadr'][df[\"id_t\"] == id_t])\n",
    "\n",
    "def tx_from_iadr(iadr):\n",
    "    return set(df['id_t'][df[\"iadr\"] == iadr])\n",
    "\n",
    "#FUNCTION TO WHICH YOU GIVE AN INPUT ADDRESS AND GET USER \n",
    "def get_user(input_adr):\n",
    "    to_inv = [input_adr]\n",
    "    user_iadrs = set()\n",
    "    seen_txs = set()\n",
    "    while to_inv:\n",
    "        current_iadr = to_inv.pop(0)\n",
    "        user_iadrs.add(current_iadr)\n",
    "        for id_t in tx_from_iadr(current_iadr):\n",
    "\n",
    "            if id_t not in seen_txs:\n",
    "                \n",
    "                seen_txs.add(id_t)\n",
    "                iadrs = iadrs_from_tx(id_t)\n",
    "                to_inv += iadrs.difference(user_iadrs) #Adding addr\n",
    "                user_iadrs.update(iadrs)\n",
    "            \n",
    "    return User(user_iadrs, seen_txs)\n",
    "\n",
    "#LIST OF LISTS OF USER AND THEIR ASSOCIATED ADDRESSES\n",
    "users = []\n",
    "\n",
    "class User:\n",
    "    def __init__(self, adrs, txs):\n",
    "        self.adr = set(adrs)\n",
    "        self.sending_tx = set(txs)\n",
    "        self.cadr = set()\n",
    "        self.receiving_tx = set(txs)\n",
    "\n",
    "# Bitcoin- \n",
    "bitcoin = User({str(0)}, set()) #Make user object with bitcoin iadr (which is 0)\n",
    "seen_miner_iadrs_tx = defaultdict(set) #Make dict associating miner payment address with tx_ids they've been involved in\n",
    "\n",
    "for index, row in df[df['iadr'] == str(0)].iterrows(): #Going through all mining txs \n",
    "    bitcoin.sending_tx.add(row['id_t']) #Adding tx id to bitcoin user's txs\n",
    "    seen_miner_iadrs_tx[row['oadr']].add(row['id_t']) # Updating dict to register the tx_id as corresponding to miners adr. If new, then new key added, otherwise added to values of existing key\n",
    "    \n",
    "users.append(bitcoin) # Add bitcoin user\n",
    "already_seen_iadr = {str(0)}  # Bitcoin iadr has already been seen\n",
    "\n",
    "# make miners users\n",
    "for adr, id_ts in seen_miner_iadrs_tx.items(): #Go through dictionary for every adr (miner) and txs he's been involved\n",
    "    miner = get_user(adr) #From an address, give back user ... aka identify all addresses belonging to miner\n",
    "    miner.adr.add(adr) #Make sure adrs and txs are added in\n",
    "    miner.sending_tx.update(id_ts)\n",
    "    users.append(miner)\n",
    "    already_seen_iadr.update(miner.adr)#Made sure miner's addresses are in already seen so that we don't create a second user with the same addresses\n",
    "    \n",
    "\n",
    "## ASSOCIATE INPUT ADDRESS AND TX WITH EACH USER IN BLOCK\n",
    "# make other users from heuristic\n",
    "for input_adr in df.iadr:\n",
    "    if input_adr not in already_seen_iadr:\n",
    "        user = get_user(input_adr)\n",
    "        users.append(user)\n",
    "        already_seen_iadr.update(user.adr)\n",
    "\n",
    "\n",
    "#TAKES OUTPUT ADDRESS AND GIVES USER THAT HAS THAT ADDRESS AS INPUT\n",
    "def user_from_oadr(oadr):\n",
    "    for i,user in enumerate(users):\n",
    "        if oadr in user.adr:\n",
    "            return i\n",
    "        \n",
    "edges = defaultdict(int)\n",
    "\n",
    "#WHICH USERS IN HAVE TRANSACTED WITH EACH OTHER\n",
    "for i,user in enumerate(users):\n",
    "    for tx_id in user.sending_tx:\n",
    "        for oadr in oadrs_from_tx(tx_id):\n",
    "            if oadr in already_seen_iadr:\n",
    "\n",
    "                    edges[(i, user_from_oadr(oadr))]+=1  \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heuristic 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open ('outfile', 'rb') as fp:\n",
    "    not_seen = pickle.load(fp)\n",
    "    \n",
    "appeared_once_o= list(df.oadr.value_counts()[df.oadr.value_counts()==1].index)\n",
    "all_iadrs= list(df.iadr.value_counts().index)\n",
    "\n",
    "o_never_used_as_i = set(appeared_once_o).difference(all_iadrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No repeats txid\n",
      "No repeats ads\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "tx_ids = []\n",
    "for user in users[1:]:#Drop out bitcoin user\n",
    "    tx_ids += list(user.sending_tx)\n",
    "\n",
    "#tx_ids = list.append([list(user.sending_tx) for user in users])\n",
    "        \n",
    "ads = []\n",
    "for i,user in enumerate(users):\n",
    "    for ad in user.adr:\n",
    "        ads.append(ad)\n",
    "        \n",
    "cads = []\n",
    "for i,user in enumerate(users):\n",
    "    for cad in user.cadr:\n",
    "        cads.append(cad)\n",
    "\n",
    "if Counter(tx_ids).most_common(10)[0][1] == 1:  ##Repeated txids between bitcoin and the miners\n",
    "    print(\"No repeats txid\")\n",
    "    \n",
    "if Counter(ads).most_common(10)[0][1] == 1:\n",
    "    print(\"No repeats ads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change Transactions\n",
    "for i,user in enumerate(users):\n",
    "    temp = set()\n",
    "    for tx_id in user.sending_tx:\n",
    "        o = oadrs_from_tx(tx_id)\n",
    "        potential_cadr = []\n",
    "        for oadr in o:\n",
    "            if oadr in not_seen and oadr in o_never_used_as_i:\n",
    "                potential_cadr.append(oadr)\n",
    "        if len(potential_cadr)==1:\n",
    "            temp.add(potential_cadr[0])\n",
    "    user.cadr.update(temp)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('id_t').agg({'oadr':['nunique', 'count'],'iadr':['nunique', 'count'],'id_txo_in':['nunique', 'count'],'id_txo_out':['nunique', 'count']})\n",
    "\n",
    "df.to_csv('users.csv', columns=['input_user','output_user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('users.pickle', 'wb') as handle:\n",
    "    pickle.dump(users, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct User Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct User Graph\n",
    "df['input_user'] = df['iadr']  \n",
    "df['output_user'] = df['oadr']\n",
    "\n",
    "#Replacing all input addresses and output addresses with a user corresponding to that address\n",
    "for i, user in enumerate(users): \n",
    "    #assert(isinstance(i, int))\n",
    "    df['input_user'] = df['input_user'].apply(lambda x: i if x in user.adr else x)\n",
    "    df['output_user'] = df['output_user'].apply(lambda x: i if x in user.adr else x)\n",
    "    df['output_user'] = df['output_user'].apply(lambda x: i if x in user.cadr else x)\n",
    "    \n",
    "for tx_id, output_user in df[['id_t','output_user']].values:\n",
    "    if isinstance(output_user,int):\n",
    "        users[output_user].receiving_tx.add(tx_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can't trust input_val column now\n",
    "# because dropped lots of inputs\n",
    "edges_df0 = df.drop_duplicates(['input_user', 'id_txo_out'])\n",
    "edges_df = edges_df0.groupby(['input_user', 'output_user']).apply(lambda group: group['output_val'].sum()).reset_index()\n",
    "#edges_df0 = edges_df0.rename(columns={0: 'edge_amount'})\n",
    "\n",
    "# edges_df2 = (\n",
    "#     df.groupby(['input_user', 'output_user'])\n",
    "#     .apply(lambda group: (group['output_val'] / group['num_txi']).sum())\n",
    "#     .reset_index()\n",
    "# )\n",
    "\n",
    "# assert((edges_df == edges_df2).all())\n",
    "\n",
    "# tups = []\n",
    "# for i in range(0, edges_df.shape[0]):\n",
    "#     tups.append((edges_df.at[i, 'input_user'],edges_df.at[i, 'output_user']))\n",
    "    \n",
    "tups = [(input_user, output_user, amount) for (index, input_user, output_user, amount) in edges_df.itertuples()]\n",
    "\n",
    "with open('./pickles/tups.pickle', 'wb') as handle:\n",
    "    pickle.dump(tups, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "#tups2 = [(input_user, output_user, amount) for (index, input_user, output_user, amount) in edges_df2.itertuples()]\n",
    "\n",
    "# assert(all(tups == tups2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{113001822}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users[1].sending_tx.intersection(users[934].receiving_tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,user in enumerate(users):\n",
    "    if len(user.adr) ==1:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df['iadr'].apply(type).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_sent</th>\n",
       "      <th>min_sent</th>\n",
       "      <th>unique_sent_adr</th>\n",
       "      <th>tx1</th>\n",
       "      <th>unique_sent_user</th>\n",
       "      <th>unique_sent</th>\n",
       "      <th>total_sent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>input_user</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.328040</td>\n",
       "      <td>0.984900</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.385590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.713700</td>\n",
       "      <td>1.250300</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.963390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.064797</td>\n",
       "      <td>0.003142</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.233997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.400641</td>\n",
       "      <td>0.239484</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.065325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.348410</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.046738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            max_sent  min_sent  unique_sent_adr  tx1  unique_sent_user  \\\n",
       "input_user                                                               \n",
       "1           2.328040  0.984900                1    1                 1   \n",
       "2           1.713700  1.250300                1    1                 1   \n",
       "3           0.064797  0.003142                1    1                 1   \n",
       "4           0.400641  0.239484                1    1                 1   \n",
       "5           1.348410  0.000200                1    1                 1   \n",
       "\n",
       "            unique_sent  total_sent  \n",
       "input_user                           \n",
       "1                     1    9.385590  \n",
       "2                     1    8.963390  \n",
       "3                     1    0.233997  \n",
       "4                     1    2.065325  \n",
       "5                     1    4.046738  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# user input features\n",
    "user_input_df = df.groupby('input_user').agg({\n",
    "    'id_txo_out': 'nunique', #Num unique times paid out\n",
    "    'oadr':'nunique', #Num of unique out addresses paid out\n",
    "    'output_user': 'nunique', #Num of unique users paid out (Out Degree)\n",
    "    #'id_txi': 'nunique', #Num unique times paid in\n",
    "    'id_t': 'nunique', #Num Txs involved in\n",
    "    'input_val': ['max', 'min']\n",
    "})\n",
    "\n",
    "user_input_df.columns = ['_'.join(col) for col in user_input_df.columns]\n",
    "\n",
    "user_input_df.rename(columns={\n",
    "    'id_txo_out_nunique': 'unique_sent',\n",
    "    'oadr_nunique': 'unique_sent_adr',\n",
    "    'output_user_nunique': 'unique_sent_user',  # (Out Degree)\n",
    "    'id_t_nunique': 'tx1',\n",
    "    'input_val_max': 'max_sent',\n",
    "    'input_val_min': 'min_sent'\n",
    "}, inplace=True)\n",
    "\n",
    "user_input_df['total_sent'] = (df['input_val'] / df['num_txo']).groupby(df['input_user']).sum()\n",
    "#dummy1 = (df['input_val'] / df['num_txo']).groupby(df['input_user']).sum()\n",
    "#dummy2 = (df['output_val'] / df['num_txi']).groupby(df['input_user']).sum()\n",
    "\n",
    "#print(user_df.tail())\n",
    "\n",
    "user_input_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_rec_adr</th>\n",
       "      <th>is_miner</th>\n",
       "      <th>unique_rec_user</th>\n",
       "      <th>max_rec</th>\n",
       "      <th>min_rec</th>\n",
       "      <th>tx2</th>\n",
       "      <th>unique_rec</th>\n",
       "      <th>total_rec</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>output_user</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>9.430000</td>\n",
       "      <td>0.165496</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>9.595496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>5.822000</td>\n",
       "      <td>5.026000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10.848000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002605</td>\n",
       "      <td>0.002605</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.003954</td>\n",
       "      <td>0.001324</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005303</td>\n",
       "      <td>0.001324</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             unique_rec_adr  is_miner  unique_rec_user   max_rec   min_rec  \\\n",
       "output_user                                                                  \n",
       "1                         6     False                2  9.430000  0.165496   \n",
       "13                        2     False                2  5.822000  5.026000   \n",
       "58                        1     False                1  0.002605  0.002605   \n",
       "59                        2     False                2  0.003954  0.001324   \n",
       "60                        2     False                2  0.005303  0.001324   \n",
       "\n",
       "             tx2  unique_rec  total_rec  \n",
       "output_user                              \n",
       "1              2           6   9.595496  \n",
       "13             2           2  10.848000  \n",
       "58             1           1   0.002605  \n",
       "59             2           2   0.005278  \n",
       "60             2           2   0.006627  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# user output features\n",
    "user_out_df = df.groupby('output_user').agg({\n",
    "    'id_txi': 'nunique', #Num unique times paid in\n",
    "    'iadr': ['nunique', lambda x: (x == str(0)).any()], #Num of unique in addresses paid this user\n",
    "    'input_user': 'nunique', #Num of unique users paid in (In Degree)\n",
    "    #'id_txo_out': 'nunique', #Num unique times paid\n",
    "    'id_t': 'nunique', #Num Txs involved in\n",
    "    'output_val': ['max', 'min']\n",
    "})\n",
    "\n",
    "user_out_df.columns = ['_'.join(col) for col in user_out_df.columns]\n",
    "\n",
    "user_out_df.rename(columns={\n",
    "    'id_txi_nunique': 'unique_rec',\n",
    "    'iadr_nunique': 'unique_rec_adr',\n",
    "    'iadr_<lambda>': 'is_miner',\n",
    "    'input_user_nunique': 'unique_rec_user',  # (In Degree)\n",
    "    'id_t_nunique': 'tx2',\n",
    "    'output_val_max': 'max_rec',\n",
    "    'output_val_min': 'min_rec'\n",
    "}, inplace=True)\n",
    "\n",
    "user_out_df['total_rec'] = (df['output_val'] / df['num_txi']).groupby(df['output_user']).sum()\n",
    "\n",
    "user_out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/ac2917/.local/lib/python3.5/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "# Merge input and output user features\n",
    "user_df = user_input_df.merge(user_out_df, how='left', left_index=True, right_index=True)\n",
    "\n",
    "# Append miners\n",
    "user_df = user_df.append(user_out_df[user_out_df['is_miner']])\n",
    "\n",
    "# Name index\n",
    "user_df.index.name = 'user'\n",
    "\n",
    "# Fill in NA values\n",
    "user_df['is_miner'].fillna(False, inplace=True)\n",
    "user_df.fillna(0, inplace=True)\n",
    "\n",
    "# New columns\n",
    "user_df['num_tx'] = user_df['tx1'] + user_df['tx2']\n",
    "# user_df = user_df.drop(['tx1', 'tx2'], axis=1)\n",
    "\n",
    "user_total_sent = [(user,total_rec) for (user, total_rec) in user_df['total_sent'].iteritems()]\n",
    "users_identified = list(user_df.index.values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Totals\n",
    "total_amt_spent = (df['input_val'] / df['num_txo']).sum() ##Total amount spent in this block?\n",
    "total_amt_recieved = (df['output_val'] / df['num_txi']).sum() ##Total amount received in this block?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw User Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "ug = igraph.Graph.TupleList(tups,directed=True,vertex_name_attr='user',edge_attrs=['amount'])\n",
    "\n",
    "ug.write_graphml('./graphml/user.graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "for u in ug.vs():\n",
    "    all_addr = []\n",
    "    node = u['user']\n",
    "    if node in list(range(len(users))):\n",
    "        a = users[node].adr\n",
    "        c = users[node].cadr\n",
    "        for address in a.union(c):\n",
    "            if address in dic.keys():\n",
    "                all_addr.append(address)\n",
    "                check = True\n",
    "    elif node in dic.keys():\n",
    "        all_addr.append(address)\n",
    "        \n",
    "    if all_addr:\n",
    "        u['tatti'] = all_addr\n",
    "    else:\n",
    "        u['tatti'] = ''                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Backup Graph\n",
    "ag = igraph.Graph.Read(\"../Graphs/400000_addr.graphml\", format = \"graphml\")\n",
    "\n",
    "for i,k in enumerate(ag.vs):\n",
    "    addr = ag.vs[i][\"name\"]\n",
    "    assigned = False\n",
    "    count = 0\n",
    "    if addr in dic.keys():\n",
    "        ag.vs[i][\"label\"] = dic[addr]\n",
    "    else:\n",
    "        ag.vs[i][\"label\"] = \"\"\n",
    "    for j, user in enumerate(users):\n",
    "        if addr in user.adr or addr in user.cadr:\n",
    "            ag.vs[i][\"user\"] = j\n",
    "            assigned = True\n",
    "            count = count +1\n",
    "    if not assigned:\n",
    "        ag.vs[i][\"user\"] = addr\n",
    "    if count>1:\n",
    "        print(\"Aw shit\")\n",
    "        \n",
    "\n",
    "ag.write_graphml('./fuckme.graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pagerank\n",
    "nodes = ig.vs['user']\n",
    "pr = ig.pagerank()\n",
    "result = list(zip(nodes, pr))\n",
    "d = dict(result)\n",
    "new_d = {k:v for k,v in d.items() if not isinstance(k,str)}\n",
    "pagerank_df = pd.DataFrame.from_dict(new_d,orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_style = {}\n",
    "visual_style[\"layout\"] = layout\n",
    "visual_style[\"bbox\"]= (10000, 10000)\n",
    "visual_style[\"margin\"] = 50\n",
    "#visual_style[\"autocurve\"] = True\n",
    "visual_style[\"vertex_label\"] = ig.vs['user']\n",
    "visual_style['edge_arrow_size'] = 0.05\n",
    "visual_style['edge_width'] = [0.03*i for i in ig.es['amount']]\n",
    "visual_style['vertex_label_size'] = 5\n",
    "visual_style['edge_curved'] = 1\n",
    "visual_style['keep_aspect_ratio'] = True\n",
    "\n",
    "size = []\n",
    "d = dict(user_total_sent)\n",
    "for k in ig.vs['user']:\n",
    "    if isinstance(k, str):\n",
    "        size.append(1)\n",
    "    else:\n",
    "        size.append(20*math.log(d[k]))\n",
    "        \n",
    "#norm = [float(i)/max(size) for i in size]\n",
    "# size = []\n",
    "# for i in ig.degree():\n",
    "#     if i > 1:\n",
    "#         size.append(20*math.log(i))\n",
    "#     else:\n",
    "#         size.append(i)\n",
    "visual_style[\"vertex_size\"] = new_list\n",
    "\n",
    "fileName = \"USER.png\"\n",
    "p = igraph.Plot(fileName, bbox=(10000, 10000), background=\"white\")\n",
    "p.add(ig, **visual_style)\n",
    "p.save(fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize data\n",
    "\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "scaled_cluster = scaler.fit_transform(user_df)\n",
    "cluster_scaled = pd.DataFrame(scaled_cluster, columns=user_df.columns, index=user_df.index)\n",
    "\n",
    "\n",
    "data_corr = cluster_scaled.corr()\n",
    "sb.heatmap(data_corr, cmap = 'bwr') #heatmap of correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into train and test sets\n",
    "clus_train, clus_test = sklearn.model_selection.train_test_split(cluster_scaled, test_size=0.3, random_state=123)\n",
    "\n",
    "clusters = range(1,10)\n",
    "meandist=[]\n",
    "\n",
    "for k in clusters:\n",
    "    model = sklearn.cluster.KMeans(n_clusters = k)\n",
    "    model.fit(clus_train)\n",
    "    clusassign=model.predict(clus_train)\n",
    "    meandist.append(sum(np.min(sp.spatial.distance.cdist(clus_train,model.cluster_centers_,'euclidean'),axis=1))/clus_train.shape[0])\n",
    "    \n",
    "plt.plot(clusters, meandist, '-o')\n",
    "#plt.subplot(2,1,1)\n",
    "plt.grid(True)\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Average distance')\n",
    "plt.title('Selecting k with the Elbow Method')\n",
    "plt.show\n",
    "\n",
    "# # Convert DataFrame to matrix\n",
    "# mat = cluster_scaled.values\n",
    "# distorsions = []\n",
    "# x = range(2, 20)\n",
    "# for k in x:\n",
    "#     #Perform K Means\n",
    "#     kmeans = sk.cluster.KMeans(n_clusters=k)\n",
    "#     kmeans.fit(mat)\n",
    "#     distorsions.append(kmeans.inertia_)\n",
    "\n",
    "# fig = plt.figure(figsize=(15, 5))\n",
    "# plt.plot(x, distorsions)\n",
    "# plt.grid(True)\n",
    "# plt.title('Elbow curve')\n",
    "# plt.show\n",
    "# plt.xticks(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.gcf().clear()\n",
    "model = sklearn.cluster.KMeans(n_clusters = 2)\n",
    "model.fit(clus_train)\n",
    "clusassign = model.predict(clus_train)\n",
    "\n",
    "colors = ['red', 'blue']\n",
    "\n",
    "#Principal Component Analysis\n",
    "pca_2 = sklearn.decomposition.PCA(2)\n",
    "plot_columns = pca_2.fit_transform(clus_train)    \n",
    "plt.scatter(x=plot_columns[:,0],y=plot_columns[:,1],c=model.labels_,cmap = matplotlib.colors.ListedColormap(colors),edgecolors = 'none')\n",
    "plt.xlabel('Canonical variable 1')\n",
    "plt.ylabel('Canonical variable 2')\n",
    "plt.title('Scatterplot of Canonical Variables for 2 clusters')\n",
    "plt.show\n",
    "\n",
    "\n",
    "# Get cluster assignment labels\n",
    "labels = model.labels_\n",
    "# Format results as a DataFrame\n",
    "data = {'transaction_id':clus_train.index,'cluster_label`':labels}\n",
    "results = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label graph with services\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Dictionary structure - \n",
    "#'Service': 'Address'\n",
    "data = pd.read_csv('./wallet_explorer/wexplorer.csv')\n",
    "service = []\n",
    "for i in range(len(data)):\n",
    "    service.append(data.iloc[i]['Col'])\n",
    "    \n",
    "block = 400000\n",
    "dic = {}\n",
    "for i in service:  \n",
    "    df = pd.read_pickle('./wallet_explorer/data_2/{}'.format(i))\n",
    "    addr = df.loc[df['last used in block'] == block]['address'].tolist()\n",
    "    dic[i] = addr\n",
    "    \n",
    "dic2 = {k:v for k,v in dic.items() if len(v)!=0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary structure - \n",
    "#'Address': 'Service'\n",
    "data = pd.read_csv('./wallet_explorer/wexplorer.csv')\n",
    "service = []\n",
    "for i in range(len(data)):\n",
    "    service.append(data.iloc[i]['Col'])\n",
    "    \n",
    "block = 400000\n",
    "dic = {}\n",
    "for i in service:  \n",
    "    df = pd.read_pickle('./wallet_explorer/data_2/{}'.format(i))\n",
    "    addr = df.loc[df['last used in block'] == block]['address'].tolist()\n",
    "    if(len(addr)!=0):\n",
    "        for a in addr:\n",
    "            dic[a] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./pickles/service_dic.pickle', 'wb') as handle:\n",
    "    pickle.dump(dic, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user']\n"
     ]
    }
   ],
   "source": [
    "import igraph\n",
    "import py2neo\n",
    "import pickle\n",
    "\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "class User:\n",
    "    def __init__(self, adrs, txs):\n",
    "        self.adr = set(adrs)\n",
    "        self.sending_tx = set(txs)\n",
    "        self.cadr = set()\n",
    "        self.receiving_tx = set(txs)\n",
    "\n",
    "def query_database(query):\n",
    "    # REMEMBER TO BE CONNECTED TO IMPERIAL WIFI!\n",
    "    graph_db = py2neo.Graph(\"https://dsi-bitcoin.doc.ic.ac.uk:7473/db/data/\", auth=(\"adi\", \"aditi123\"))\n",
    "    return graph_db.run(query)\n",
    "\n",
    "def get_block_data(first_block, last_block):\n",
    "    query_string = \"\"\"\n",
    "                    MATCH (b:Block) <-[:MINED_IN]- (t:Tx) <-[:IN]- (txi:TxIn) <-[:UNLOCK]- (iadr:Address)\n",
    "                    WHERE b.height >= {} AND b.height <= {}\n",
    "                    MATCH (txi) <-[:SPENT]- (txo_in:TxOut)\n",
    "                    MATCH (oadr:Address) <-[:LOCK]- (txo_out:TxOut) <-[:OUT]- (t)\n",
    "\n",
    "                    RETURN iadr.address as iadr, oadr.address as oadr\n",
    "                    \"\"\".format(first_block, last_block)\n",
    "    return query_string\n",
    "\n",
    "def address_graph(result,dic,users):\n",
    "    #tups1 = []\n",
    "    #for d in result:\n",
    "    #    tups1.append((d['iadr'],d['oadr']))\n",
    "    #ag = igraph.Graph.TupleList(tups1,directed=True,vertex_name_attr='addr')\n",
    "    ag = igraph.Graph.Read(\"../Graphs/400000_addr.graphml\", format = \"graphml\")\n",
    "\n",
    "    for i,k in enumerate(ag.vs):\n",
    "        \n",
    "        a = ag.vs[i][\"name\"]\n",
    "        assigned = False\n",
    "        if a in dic.keys():\n",
    "            ag.vs[i][\"Label\"] = dic[a]\n",
    "        else:\n",
    "            ag.vs[i][\"Label\"] = \"\"\n",
    "        for j, user in enumerate(users):\n",
    "            if a in user.adr or a in user.cadr:\n",
    "                var = j\n",
    "                assigned = True\n",
    "        if not assigned:\n",
    "            var = a\n",
    "        ag.vs[i][\"user\"] = str(var)\n",
    "    ag.write_graphml('./graphml/addr.graphml')\n",
    "    return ag\n",
    "\n",
    "def user_graph(tups):\n",
    "    ug = igraph.Graph.TupleList(tups,directed=True,vertex_name_attr='user',edge_attrs=['amount'])\n",
    "\n",
    "    for u in ug.vs():\n",
    "        all_addr = ''\n",
    "        node = u['user']\n",
    "        if node in list(range(len(users))):\n",
    "            a = users[node].adr\n",
    "            c = users[node].cadr\n",
    "            for address in a.union(c):\n",
    "                if address in dic.keys():\n",
    "                    all_addr += \" {} \".format(address)\n",
    "                    check = True\n",
    "        elif node in dic.keys():\n",
    "            all_addr += \" {} \".format(address)\n",
    "\n",
    "        if all_addr:\n",
    "            u['user'] = all_addr\n",
    "        else:\n",
    "            u['user'] = ''\n",
    "    \n",
    "    \n",
    "    print(ug.vertex_attributes())\n",
    "\n",
    "    ug.write_graphml('./graphml/user.graphml')\n",
    "    return ug\n",
    "\n",
    "with open('./pickles/tups.pickle', 'rb') as handle:\n",
    "    tups = pickle.load(handle)\n",
    "with open('./pickles/service_dic.pickle', 'rb') as handle:\n",
    "    dic = pickle.load(handle)\n",
    "with open('./pickles/users.pickle', 'rb') as handle:\n",
    "    users = pickle.load(handle)\n",
    "#result = query_database(get_block_data(400000,400000))\n",
    "result = 0\n",
    "new_ag = address_graph(result,dic,users)\n",
    "new_ug = user_graph(tups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'name']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ag = igraph.Graph.Read(\"../Graphs/400000_addr.graphml\", format = \"graphml\")\n",
    "ag.vertex_attributes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'user', 'name', 'Label']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ag.vertex_attributes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/ac2917/.local/lib/python3.5/site-packages/igraph/__init__.py:2223: RuntimeWarning: Could not add vertex ids, there is already an 'id' vertex attribute at foreign-graphml.c:443\n",
      "  return reader(f, *args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['id', 'user', 'name', 'Label']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newer_ag = igraph.Graph.Read(\"./graphml/addr.graphml\", format = \"graphml\")\n",
    "newer_ag.vertex_attributes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ug.vertex_attributes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newer_ug = igraph.Graph.Read(\"./graphml/user.graphml\", format = \"graphml\")\n",
    "newer_ug.vertex_attributes()\n",
    "\n",
    "for i in new_ug.vs():\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
