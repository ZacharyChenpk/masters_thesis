{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import sklearn.preprocessing\n",
    "import sklearn.decomposition\n",
    "import sklearn.model_selection\n",
    "import sklearn.cluster\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import py2neo\n",
    "import seaborn as sb ##includes convenient heatmaps and boxplots\n",
    "import scipy as sp\n",
    "import pylab as pl\n",
    "from sklearn.metrics import silhouette_score\n",
    "from collections import Counter\n",
    "import time\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_database(query):\n",
    "    # REMEMBER TO BE CONNECTED TO IMPERIAL WIFI!\n",
    "    graph_db = py2neo.Graph(\"https://dsi-bitcoin.doc.ic.ac.uk:7473/db/data/\", auth=(\"adi\", \"aditi123\"))\n",
    "    return graph_db.run(query)\n",
    "\n",
    "def get_block_data(first_block, last_block):\n",
    "    query_string = \"\"\"\n",
    "                    MATCH (b:Block) <-[:MINED_IN]- (t:Tx) <-[:IN]- (txi:TxIn) <-[:UNLOCK]- (iadr:Address)\n",
    "                    WHERE b.height >= {} AND b.height <= {}\n",
    "                    MATCH (txi) <-[:SPENT]- (txo_in:TxOut) \n",
    "                    MATCH (oadr:Address) <-[:LOCK]- (txo_out:TxOut) <-[:OUT]- (t)\n",
    "                    \n",
    "                    RETURN iadr.address as iadr, oadr.address as oadr, txo_in.value as input_val, txo_out.value as output_val, ID(txo_in) as id_txo_in, ID(txi) as id_txi, ID(t) as id_t, ID(txo_out) as id_txo_out\n",
    "                    \"\"\".format(first_block, last_block)\n",
    "    return query_string\n",
    "\n",
    "def write_to_csv(result,string):\n",
    "\n",
    "    df = result.to_data_frame()\n",
    "\n",
    "    if (df.empty):\n",
    "        print(\"Something went wrong, there is no data for this/these blocks\")\n",
    "    else:\n",
    "        df.to_csv('{}.csv'.format(string), encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = query_database(get_block_data(400000,400000))\n",
    "df = result.to_data_frame()\n",
    "\n",
    "#df = pd.read_csv('block_400000.csv')\n",
    "#df[[col for col in df.columns if not 'Unnamed' in col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if any columns are unique\n",
    "for column in df:\n",
    "    print(df[column].is_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['oadr'].value_counts().sort_values(ascending=False))\n",
    "df1 = df.loc[df['iadr'] == '1BQLNJtMDKmMZ4PyqVFfRuBNvoGhjigBKF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counting the number of shared input addresses per transaction\n",
    "\n",
    "tx_ids = []\n",
    "    \n",
    "for val in df.id_t.value_counts().iteritems():\n",
    "    tx_ids.append(val[0])\n",
    "\n",
    "def iadrs_from_tx(id_t):\n",
    "    return list(df['iadr'][df[\"id_t\"] == id_t])\n",
    "\n",
    "\n",
    "for t in tx_ids:\n",
    "    dummy = iadrs_from_tx(t)\n",
    "    print (t)\n",
    "    break\n",
    "    \n",
    "\n",
    "Counter(dummy) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature extraction\n",
    "cluster = (\n",
    "    df.groupby('id_t')\n",
    "    .agg({\n",
    "        'input_val': 'sum',\n",
    "        'id_txi': 'nunique',\n",
    "        'id_txo_out': 'nunique',\n",
    "        'iadr': 'nunique',\n",
    "        'oadr': 'nunique',       \n",
    "    }).rename(columns = {\n",
    "        'iadr':'num_unique_addr_in',\n",
    "        'oadr':'num_unique_addr_out',\n",
    "        'input_val':'total_val'\n",
    "    })\n",
    ")\n",
    "\n",
    "cluster['total_val'] = cluster['total_val']/cluster['id_txo_out']\n",
    "\n",
    "cluster['ratio'] = cluster['id_txi'] / cluster['id_txo_out']\n",
    "cluster['degree'] = cluster['id_txi'] + cluster['id_txo_out'] \n",
    "\n",
    "cluster = cluster.drop(['id_txi', 'id_txo_out'],axis = 1)\n",
    "\n",
    "#Normalize data\n",
    "\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "scaled_cluster = scaler.fit_transform(cluster)\n",
    "cluster_scaled = pd.DataFrame(scaled_cluster, columns=cluster.columns, index=cluster.index)\n",
    "\n",
    "#CHECK RandomizedPCA with whiten=True\n",
    "\n",
    "#Principal Component Analysis - DIMENSIONALITY REDUCTION\n",
    "pca = sklearn.decomposition.PCA()\n",
    "plot_columns = pca.fit_transform(cluster_scaled)   \n",
    "#cmap = matplotlib.colors.ListedColormap(colors),\n",
    "plt.scatter(x=plot_columns[:,0],y=plot_columns[:,1])\n",
    "plt.xlabel('Canonical variable 1')\n",
    "plt.ylabel('Canonical variable 2')\n",
    "plt.title('Scatterplot of Canonical Variables for 4 clusters')\n",
    "plt.show\n",
    "\n",
    "print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))\n",
    "\n",
    "df_pca = cluster_scaled\n",
    "df_pca['pca_1'] = plot_columns[:,0]\n",
    "df_pca['pca_2'] = plot_columns[:,1]\n",
    "df_pca['pca_3'] = plot_columns[:,1]\n",
    "df_pca['pca_4'] = plot_columns[:,1]\n",
    "\n",
    "feat_col=['pca_1', 'pca_2', 'pca_3', 'pca_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_corr = cluster_scaled.corr()\n",
    "# sb.heatmap(data_corr, cmap = 'bwr') #heatmap of correlation matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering - PCA and KMeans combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into train and test sets\n",
    "#clus_train, clus_test = sklearn.model_selection.train_test_split(df_pca.loc[:,feat_col], test_size=0.3, random_state=123)\n",
    "\n",
    "clus_df = df_pca.loc[:,feat_col]\n",
    "\n",
    "clusters = range(2,10)\n",
    "meandist=[]\n",
    "distortions = []\n",
    "ss = []\n",
    "\n",
    "for k in clusters:\n",
    "    model = sklearn.cluster.KMeans(n_clusters = k)\n",
    "    model.fit(clus_df)\n",
    "    meandist.append(sum(np.min(sp.spatial.distance.cdist(clus_df,model.cluster_centers_,'euclidean'),axis=1))/clus_df.shape[0])\n",
    "    #distorsions.append(model.inertia_) \n",
    "    distortions.append(sum(np.min(cdist(clus_df, model.cluster_centers_, 'euclidean'), axis=1)) / clus_df.shape[0])\n",
    "    ss.append(silhouette_score(clus_df, model.labels_))\n",
    "\n",
    "# Plot the elbow\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(clusters, distortions, 'bx-')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(clusters, meandist, '-o')\n",
    "plt.title('Selecting k with the Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Average distance')\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(clusters, distorsions, '-o')\n",
    "# plt.title('Selecting k with the Elbow Method')\n",
    "# plt.xlabel('Number of clusters')\n",
    "# plt.ylabel('Model inertia')\n",
    "\n",
    "plt.show\n",
    "plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the elbow\n",
    "plt.plot(clusters, ss, 'bx-')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sklearn.cluster.KMeans(n_clusters = 3)\n",
    "model.fit(clus_df)\n",
    "model.predict(clus_df)\n",
    "\n",
    "ss = silhouette_score(clus_df, model.labels_, metric='euclidean')\n",
    "print(\"\\nSilhouette Score: %f\" % ss)\n",
    "\n",
    "clus = pd.DataFrame({'cluster_label': model.labels_})\n",
    "clus = clus.set_index((clus_df.index))\n",
    "\n",
    "try: \n",
    "    clus_df = clus_df.join(clus)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "plt.scatter(x=clus_df['pca_1'].values,y=clus_df['pca_2'].values,c=model.labels_,edgecolors = 'none')\n",
    "plt.xlabel('Canonical variable 1')\n",
    "plt.ylabel('Canonical variable 2')\n",
    "plt.title('Scatterplot of Canonical Variables for 4 clusters')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################l\n",
    "#Barplot of member counts\n",
    "print(Counter(model.labels_))\n",
    "clustered_series = pd.Series(data=model.labels_.flatten())\n",
    "plt.barh(\n",
    "    range(len(clustered_series.value_counts())),\n",
    "    clustered_series.value_counts()\n",
    ")\n",
    "\n",
    "locs, labels = plt.xticks()\n",
    "plt.yticks(np.arange(0,len(clustered_series.value_counts()), step=1))\n",
    "\n",
    "plt.title('Cluster Member Counts')\n",
    "plt.xlabel('Transactions in Cluster')\n",
    "plt.ylabel('Cluster Number');\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_group = clus_df.groupby('cluster_label').mean()\n",
    "print(cluster_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_col=['num_unique_addr_in', 'total_val', 'num_unique_addr_out', 'ratio','degree']\n",
    "\n",
    "time_start = time.time()\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(clus_df)\n",
    "\n",
    "print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "\n",
    "df_tsne = clus_df\n",
    "df_tsne['x-tsne'] = tsne_results[:,0]\n",
    "df_tsne['y-tsne'] = tsne_results[:,1]\n",
    "\n",
    "chart = ggplot( df_tsne, aes(x='x-tsne', y='y-tsne', color='cluster_label') ) \\\n",
    "        + geom_point(size=70,alpha=1) \\\n",
    "        + ggtitle(\"tSNE dimensions colored by cluster\")\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN - Try OPTICS as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################l\n",
    "#DBSCAN Clustering\n",
    "\n",
    "clf = sklearn.cluster.DBSCAN(eps=1.9, min_samples=3)\n",
    "clf.fit(clus_df)\n",
    "labels = clf.labels_\n",
    "print(Counter(labels))\n",
    "\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "print(\"\\nClusters discovered: %d\" % n_clusters_)\n",
    "\n",
    "ss = silhouette_score(clus_df, labels, metric='euclidean')\n",
    "print(\"\\nSilhouette Score: %f\" % ss)\n",
    "\n",
    "################################################################################################################l\n",
    "#Principal Component Analysis\n",
    "\n",
    "colors = ['red', 'blue', 'yellow','black']\n",
    "pca_2 = sklearn.decomposition.PCA(2)\n",
    "plot_columns = pca_2.fit_transform(clus_df)    \n",
    "plt.scatter(x=plot_columns[:,0],y=plot_columns[:,1],c=labels,cmap = matplotlib.colors.ListedColormap(colors),edgecolors = 'none')\n",
    "plt.xlabel('Canonical variable 1')\n",
    "plt.ylabel('Canonical variable 2')\n",
    "plt.title('Scatterplot of Canonical Variables for 4 clusters')\n",
    "plt.show\n",
    "\n",
    "# Get cluster assignment labels\n",
    "labels = model.labels_\n",
    "# Format results as a DataFrame\n",
    "data = {'transaction_id':clus_df.index,'cluster_label':labels}\n",
    "results = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining statistics of inputs, outputs of a transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_ids = []\n",
    "tx_id_val = []\n",
    "txo_in_ids = []\n",
    "txo_out_ids = []\n",
    "iadr = []\n",
    "oadr = []\n",
    "txi_ids = []\n",
    "\n",
    "\n",
    "for val in df.iadr.value_counts().iteritems():\n",
    "    iadr.append(val[0])\n",
    "\n",
    "for val in df.id_txi.value_counts().iteritems():\n",
    "    txi_ids.append(val[0])\n",
    "    \n",
    "    \n",
    "for val in df.oadr.value_counts().iteritems():\n",
    "    oadr.append(val[0])\n",
    "    \n",
    "for val in df.id_t.value_counts().iteritems():\n",
    "    tx_ids.append(val[0])\n",
    "    data = df[df.id_t==val[0]]\n",
    "    tx_id_val.append(data.output_val.sum())\n",
    "    \n",
    "\n",
    "for val in df.id_txo_in.value_counts().iteritems():\n",
    "    txo_in_ids.append(val[0])\n",
    "    \n",
    "for val in df.id_txo_out.value_counts().iteritems():\n",
    "    txo_out_ids.append(val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(txo_in_ids))\n",
    "print(len(txi_ids))\n",
    "print(len(tx_ids))\n",
    "print(len(txo_out_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = set(txo_in_ids).intersection(txo_out_ids)\n",
    "print(len(matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(iadr))\n",
    "print(len(oadr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = set(iadr).intersection(oadr)\n",
    "len(matches)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
