{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from functools import reduce\n",
    "import pickle\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "first_block = 400036\n",
    "last_block = 400036\n",
    "\n",
    "class User:\n",
    "    def __init__(self, adrs, txs):\n",
    "        self.adr = set(adrs)\n",
    "        self.sending_tx = set(txs)\n",
    "        self.cadr = set()\n",
    "        self.receiving_tx = set(txs)\n",
    "        \n",
    "#CHANGE LATER TO QUERY DATABASE INSTEAD\n",
    "def iadrs_from_tx(id_t):\n",
    "    return set(df['iadr'][df[\"id_t\"] == id_t])\n",
    "\n",
    "def oadrs_from_tx(id_t):\n",
    "    return set(df['oadr'][df[\"id_t\"] == id_t])\n",
    "\n",
    "def tx_from_iadr(iadr):\n",
    "    return set(df['id_t'][df[\"iadr\"] == iadr])\n",
    "\n",
    "#FUNCTION TO WHICH YOU GIVE AN INPUT ADDRESS AND GET USER \n",
    "def get_user(input_adr):\n",
    "    to_inv = [input_adr]\n",
    "    user_iadrs = set()\n",
    "    seen_txs = set()\n",
    "    while to_inv:\n",
    "        current_iadr = to_inv.pop(0)\n",
    "        user_iadrs.add(current_iadr)\n",
    "        for id_t in tx_from_iadr(current_iadr):\n",
    "\n",
    "            if id_t not in seen_txs:\n",
    "                \n",
    "                seen_txs.add(id_t)\n",
    "                iadrs = iadrs_from_tx(id_t)\n",
    "                to_inv += iadrs.difference(user_iadrs) #Adding addr\n",
    "                user_iadrs.update(iadrs)\n",
    "            \n",
    "    return User(user_iadrs, seen_txs)\n",
    "\n",
    "#TAKES OUTPUT ADDRESS AND GIVES USER THAT HAS THAT ADDRESS AS INPUT\n",
    "def user_from_oadr(oadr):\n",
    "    for i,user in enumerate(users):\n",
    "        if oadr in user.adr:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIST OF LISTS OF USER AND THEIR ASSOCIATED ADDRESSES\n",
    "users = []\n",
    "starttime = time.time()\n",
    "total_df = pd.DataFrame()\n",
    "for block in range(first_block,last_block+1,1):\n",
    "    df = pd.read_pickle(\"../pickles/df/{}.pickle\".format(block))\n",
    "    # New columns for number of input and output transaction ids\n",
    "    df['num_txo'] = df.groupby('id_t')['id_txo_out'].transform('nunique')\n",
    "    df['num_txi'] = df.groupby('id_t')['id_txi'].transform('nunique')\n",
    "\n",
    "    # Bitcoin- \n",
    "    bitcoin = User({str(0)}, set()) #Make user object with bitcoin iadr (which is 0)\n",
    "    seen_miner_iadrs_tx = defaultdict(set) #Make dict associating miner payment address with tx_ids they've been involved in\n",
    "\n",
    "    for index, row in df[df['iadr'] == str(0)].iterrows(): #Going through all mining txs\n",
    "        bitcoin.sending_tx.add(row['id_t']) #Adding tx id to bitcoin user's txs\n",
    "        seen_miner_iadrs_tx[row['oadr']].add(row['id_t']) # Updating dict to register the tx_id as corresponding to miners adr. If new, then new key added, otherwise added to values of existing key\n",
    "\n",
    "    users.append(bitcoin) # Add bitcoin user\n",
    "    already_seen_iadr = {str(0)}  # Bitcoin iadr has already been seen\n",
    "\n",
    "    # make miners users\n",
    "    for adr, id_ts in seen_miner_iadrs_tx.items(): #Go through dictionary for every adr (miner) and txs he's been involved\n",
    "        miner = get_user(adr) #From an address, give back user ... aka identify all addresses belonging to miner\n",
    "        miner.adr.add(adr) #Make sure adrs and txs are added in\n",
    "        miner.receiving_tx.update(id_ts)\n",
    "        users.append(miner)\n",
    "        already_seen_iadr.update(miner.adr)#Made sure miner's addresses are in already seen so that we don't create a second user with the same addresses\n",
    "\n",
    "    ## ASSOCIATE INPUT ADDRESS AND TX WITH EACH USER IN BLOCK\n",
    "    # make other users from heuristic\n",
    "    for input_adr in df.iadr:\n",
    "        if input_adr not in already_seen_iadr:\n",
    "            user = get_user(input_adr)\n",
    "            users.append(user)\n",
    "            already_seen_iadr.update(user.adr)\n",
    "\n",
    "\n",
    "    edges = defaultdict(int)\n",
    "\n",
    "    #WHICH USERS IN HAVE TRANSACTED WITH EACH OTHER\n",
    "    for i,user in enumerate(users):\n",
    "        for tx_id in user.sending_tx:\n",
    "            for oadr in oadrs_from_tx(tx_id):\n",
    "                if oadr in already_seen_iadr:\n",
    "\n",
    "                        edges[(i, user_from_oadr(oadr))]+=1  \n",
    "\n",
    "    print(\"Total time to process heuristic 1:\", time.time()-starttime)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding users by using heuristic measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heuristic 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time to process heuristic 1: 679.7185869216919\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heuristic 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time to process heuristic 2: 31.896567344665527\n"
     ]
    }
   ],
   "source": [
    "otc_dic = {}\n",
    "for block in range(first_block,last_block+1,1):\n",
    "    with open ('../pickles/otc/otc_{}.pickle'.format(block), 'rb') as fp:\n",
    "        otc_dic[block] = pickle.load(fp)\n",
    "not_seen = list(reduce(set.symmetric_difference, (set(val) for val in otc_dic.values())))\n",
    "\n",
    "#appeared_once_o= list(df.oadr.value_counts()[df.oadr.value_counts()==1].index)\n",
    "#all_iadrs= list(df.iadr.value_counts().index)\n",
    "#temp_df = df.loc[df['num_txo'] > 1]    #Don't regard any txs that only output to one address\n",
    "#all_oadrs = set(df.oadr) #Remove all repeating adrs\n",
    "#all_iadrs= set(df.iadr)\n",
    "#o_never_used_as_i = set(appeared_once_o).difference(all_iadrs)\n",
    "\n",
    "starttime = time.time()    \n",
    "#Change Transactions\n",
    "\n",
    "#for a transaction (not coinbase), if only one of the output addresses is appearing for the first time\n",
    "#and this output address has not already been seen in the user, then this is a change address\n",
    "\n",
    "for i,user in enumerate(users):\n",
    "    cadrs_for_user = set()\n",
    "    for tx_id in user.sending_tx:    #CHECK THIS\n",
    "        o = oadrs_from_tx(tx_id)\n",
    "        potential_cadr = []\n",
    "        for oadr in o:\n",
    "            if oadr in not_seen and oadr not in user.adr:\n",
    "                potential_cadr.append(oadr)\n",
    "        if len(potential_cadr)==1:\n",
    "            cadrs_for_user.add(potential_cadr[0])\n",
    "            not_seen.remove(potential_cadr[0]) #Ensure that same change address won't be assigned to another user\n",
    "    user.cadr.update(cadrs_for_user)\n",
    "    \n",
    "print(\"Total time to process heuristic 2:\", time.time()-starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No repeats txid\n",
      "No repeats ads\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "tx_ids = []\n",
    "for user in users[1:]:#Drop out bitcoin user\n",
    "    tx_ids += list(user.sending_tx)\n",
    "\n",
    "#tx_ids = list.append([list(user.sending_tx) for user in users])\n",
    "        \n",
    "ads = []\n",
    "for i,user in enumerate(users):\n",
    "    for ad in user.adr:\n",
    "        ads.append(ad)\n",
    "        \n",
    "cads = []\n",
    "for i,user in enumerate(users):\n",
    "    for cad in user.cadr:\n",
    "        cads.append(cad)\n",
    "\n",
    "if Counter(tx_ids).most_common(10)[0][1] == 1:  ##Repeated txids between bitcoin and the miners\n",
    "    print(\"No repeats txid\")\n",
    "    \n",
    "if Counter(ads).most_common(10)[0][1] == 1:\n",
    "    print(\"No repeats ads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Users found\n",
    "with open('../pickles/users/users_{}_to_{}.pickle'.format(first_block,last_block),'wb') as f:\n",
    "    pickle.dump(users,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Users found\n",
    "with open('../pickles/users/users_{}_to_{}.pickle'.format(first_block,last_block), 'rb') as f:\n",
    "    users = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to_combine length  3027\n",
      "10943\n",
      "to_combine length  744\n",
      "10535\n",
      "to_combine length  328\n",
      "10383\n",
      "to_combine length  162\n",
      "10351\n",
      "to_combine length  129\n",
      "10331\n",
      "to_combine length  109\n",
      "10320\n",
      "to_combine length  98\n",
      "10312\n",
      "to_combine length  90\n",
      "10306\n",
      "to_combine length  84\n",
      "10300\n",
      "to_combine length  78\n",
      "10294\n",
      "to_combine length  72\n",
      "10288\n",
      "to_combine length  66\n",
      "10283\n",
      "to_combine length  61\n",
      "10278\n",
      "to_combine length  56\n",
      "10273\n",
      "to_combine length  51\n",
      "10270\n",
      "to_combine length  47\n",
      "10267\n",
      "to_combine length  43\n",
      "10264\n",
      "to_combine length  39\n",
      "10261\n",
      "to_combine length  36\n",
      "10258\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-156-3e59c5618837>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0musers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mto_combine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetCouples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-156-3e59c5618837>\u001b[0m in \u001b[0;36mgetCouples\u001b[0;34m(users)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mto_combine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0motheruser\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcadr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0motheruser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0mto_combine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def getCouples(users):\n",
    "    to_combine = []\n",
    "    for i, user in enumerate(users):\n",
    "        for k, otheruser in enumerate(users):\n",
    "            if user.cadr.intersection(otheruser.adr) and i!=k:\n",
    "                to_combine.append((i,k))\n",
    "    return to_combine\n",
    "print(len(users))\n",
    "to_combine = getCouples(users)\n",
    "while to_combine:\n",
    "    print(\"to_combine length \", len(to_combine))\n",
    "    st = set(users)\n",
    "    for tple in to_combine:\n",
    "        user1 = users[tple[0]]\n",
    "        user2 = users[tple[1]]\n",
    "        if user1 in st and user2 in st:\n",
    "            #print(tple)\n",
    "            st.remove(user1)\n",
    "            st.remove(user2)\n",
    "            user1.adr = user1.adr.union(user2.adr)\n",
    "            user1.cadr = user1.cadr.union(user2.cadr)\n",
    "            st.add(user1)\n",
    "    users = list(st)\n",
    "    print(len(users))\n",
    "    to_combine = getCouples(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.groupby('id_t').agg({'oadr':['nunique', 'count'],'iadr':['nunique', 'count'],'id_txo_in':['nunique', 'count'],'id_txo_out':['nunique', 'count']})\n",
    "#df.to_csv('users.csv', columns=['input_user','output_user'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactions between users (constructing user graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct User Graph\n",
    "df['input_user'] = df['iadr']  \n",
    "df['output_user'] = df['oadr']\n",
    "\n",
    "starttime = time.time() \n",
    "#Replacing all input addresses and output addresses with a user corresponding to that address\n",
    "for i, user in enumerate(users): \n",
    "    #assert(isinstance(i, int))\n",
    "    df['input_user'] = df['input_user'].apply(lambda x: i if x in user.adr else x)\n",
    "    df['output_user'] = df['output_user'].apply(lambda x: i if x in user.adr else x)\n",
    "    df['output_user'] = df['output_user'].apply(lambda x: i if x in user.cadr else x)\n",
    "    \n",
    "for tx_id, output_user in df[['id_t','output_user']].values:\n",
    "    if isinstance(output_user,int):\n",
    "        users[output_user].receiving_tx.add(tx_id)\n",
    "print(\"Total time to construct user graph:\", time.time()-starttime)\n",
    "\n",
    "df.to_pickle(\"../pickles/df/{}_to_{}_users.pickle\".format(first_block,last_block))\n",
    "#Save Users found\n",
    "with open('../pickles/users/users_{}_to_{}.pickle'.format(first_block,last_block),'wb') as f:\n",
    "    pickle.dump(users,f)\n",
    "    \n",
    "# can't trust input_val column now\n",
    "# because dropped lots of inputs\n",
    "edges_df0 = df.drop_duplicates(['input_user', 'id_txo_out'])\n",
    "edges_df = edges_df0.groupby(['input_user', 'output_user']).apply(lambda group: group['output_val'].sum()).reset_index()\n",
    "#edges_df0 = edges_df0.rename(columns={0: 'edge_amount'})\n",
    "\n",
    "# edges_df2 = (\n",
    "#     df.groupby(['input_user', 'output_user'])\n",
    "#     .apply(lambda group: (group['output_val'] / group['num_txi']).sum())\n",
    "#     .reset_index()\n",
    "# )\n",
    "\n",
    "# assert((edges_df == edges_df2).all())\n",
    "\n",
    "# tups = []\n",
    "# for i in range(0, edges_df.shape[0]):\n",
    "#     tups.append((edges_df.at[i, 'input_user'],edges_df.at[i, 'output_user']))\n",
    "    \n",
    "tups = [(input_user, output_user, amount) for (index, input_user, output_user, amount) in edges_df.itertuples()]\n",
    "\n",
    "with open(\"../pickles/user_graphs/{}_to_{}_users.pickle\".format(first_block,last_block), 'wb') as f:\n",
    "    pickle.dump(tups,f)\n",
    "#tups2 = [(input_user, output_user, amount) for (index, input_user, output_user, amount) in edges_df2.itertuples()]\n",
    "\n",
    "# assert(all(tups == tups2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df['iadr'].apply(type).value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
