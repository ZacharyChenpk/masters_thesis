{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ml import *\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# label_df = pd.read_pickle(\"../pickles/upsampled_users/user_df_labelled_5_new.pickle\")\n",
    "# label_df = label_df[label_df.category != 'mixed']\n",
    "# #label_df = label_df.reset_index()\n",
    "# val_df = label_df[30000:42114]\n",
    "# val_df.to_pickle(\"./val_df.pickle\")\n",
    "# label_df = label_df[0:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_df = pd.read_pickle(\"../pickles/upsampled_users/user_df_labelled_5_new.pickle\")\n",
    "label_df = label_df[label_df.category != 'mixed']\n",
    "Y = label_df.category\n",
    "X = label_df.drop(columns = [\"category\"])\n",
    "X, X_val, Y, y_val = train_test_split(X, Y, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X['category'] = Y\n",
    "label_df = X\n",
    "x1 = label_df.loc[label_df['category']=='exchanges']\n",
    "x2 = label_df.loc[label_df['category']=='gambling']\n",
    "x3 = label_df.loc[label_df['category']=='pool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns = [\n",
    "       'num_receiving_tx_b',  'num_sending_tx_b', \n",
    "       'num_tx_a', 'num_tx_b', 'total_rec_a', 'total_rec_b',\n",
    "       'total_rec_t',  'total_sent_a', 'total_sent_b',\n",
    "       'total_sent_t', 'unique_rec_adr_b',\n",
    "       'unique_rec_b', 'unique_rec_user_b',\n",
    "       'unique_sent_adr_b', 'unique_sent_b',\n",
    "       'unique_sent_user_b'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_correlation = df.corr(method='spearman')\n",
    "print(\"correlation: \")\n",
    "data_correlation.style.format(\"{:.2}\").background_gradient(cmap=plt.cm.Greens, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_correlation[(abs(data_correlation) > 0.8) & ( data_correlation != 1.0)].dropna(how=\"all\", axis=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indices = data_correlation.index\n",
    "fig = plt.figure(figsize = (12,12))\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(data_correlation, vmin=-1, vmax=1, cmap=plt.cm.Greens)\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0,len(indices),1)\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "plt.xticks(rotation=90)\n",
    "ax.set_xticklabels(indices, fontsize=8)\n",
    "ax.set_yticklabels(indices, fontsize=8)\n",
    "plt.grid()\n",
    "plt.savefig(\"correlation_matrix.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_hist(label_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def downsample(big_class, small_class):\n",
    "    indices = np.arange(big_class.shape[0])\n",
    "    random_indices = np.random.choice(indices, size = small_class.shape[0])\n",
    "    downsampled_class = big_class.iloc[random_indices] # choose random staying customers\n",
    "    return downsampled_class\n",
    "\n",
    "x1 = downsample(x1,x3)\n",
    "x2 = downsample(x2,x3)\n",
    "\n",
    "temp = pd.concat([x1, x2])\n",
    "df = pd.concat([temp,x3])\n",
    "\n",
    "# df = df.reset_index()\n",
    "# df = df.sort_values(by=['index'])\n",
    "# df = df.drop(columns = [\"index\",\"user\"])\n",
    "#Shuffling all data\n",
    "Y = df.category\n",
    "#Y = LabelEncoder().fit_transform(Y)\n",
    "#classes, Y = np.unique(Y, return_inverse=True)\n",
    "X = df.drop(columns = [\"category\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Keeping time element\n",
    "# X_1 = df[0:35000]\n",
    "# X_2 = df[35000:40000]\n",
    "# y_train = X_1.category\n",
    "# y_test = X_2.category\n",
    "# X_train = X_1.drop(columns=['category'])\n",
    "# X_test = X_2.drop(columns=['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dec_tree_classifier, y_pred = get_best_dec_tree(X_train=X_train, y_train=y_train,\n",
    "                                       X_test=X_test, y_test=y_test)\n",
    "\n",
    "#sum(y_pred == y_test) / len(y_test)\n",
    "# import pickle\n",
    "# # now you can save it to a file\n",
    "# with open('dt_gambling.pickle', 'wb') as f:\n",
    "#     pickle.dump(dec_tree_classifier, f)\n",
    "    \n",
    "scores(y_test, y_pred)\n",
    "print(\"saving confusion matrix for decision tree...\")\n",
    "plot_confusion_matrix(y_test, y_pred, \"decision_tree_downsampled_conf_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##test on unseen data\n",
    "print(Counter(y_val))\n",
    "y_val_pred = dec_tree_classifier.predict(X_val)\n",
    "scores(y_val, y_val_pred)\n",
    "plot_confusion_matrix(y_val, y_val_pred, \"decision_tree_downsampled_conf_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_tree = tree.DecisionTreeClassifier(random_state=42, class_weight=\"balanced\")\n",
    "param_grid = dict(max_depth=list(range(1, 40)))\n",
    "\n",
    "best_params = get_best_estimator_params(dec_tree, param_grid, X,Y)\n",
    "\n",
    "dec_tree = tree.DecisionTreeClassifier(max_depth = best_params['max_depth'], random_state=42,  class_weight=\"balanced\")\n",
    "dec_tree.fit(X, Y)\n",
    "\n",
    "y_val_pred = dec_tree.predict(X_val)\n",
    "\n",
    "scores(y_val, y_val_pred)\n",
    "plot_confusion_matrix(y_val, y_val_pred, \"decision_tree_downsampled_conf_matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Decision Tree upto a few depth layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"save decision tree with few depth layers for visualization: \")\n",
    "dec_tree = tree.DecisionTreeClassifier(max_depth = 19, random_state=42, class_weight=\"balanced\")\n",
    "dec_tree = dec_tree.fit(X_train, y_train)\n",
    "y_pred = dec_tree.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "#plot_dec_tree(dec_tree, feature_names=X_train.columns, filename=\"Decision Tree\")\n",
    "plot_confusion_matrix(y_test, y_pred, \"decision_tree_downsampled_conf_matrix\")\n",
    "scores(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf_classifier, y_pred = get_best_random_forest(X_train=X_train, y_train=y_train,\n",
    "                                       X_test=X_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"saving confusion matrix ...\")\n",
    "plot_confusion_matrix(y_test, y_pred, \"random_forest_conf_mat.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##test on unseen data\n",
    "print(Counter(y_val))\n",
    "y_val_pred = rf_classifier.predict(X_val)\n",
    "scores(y_val, y_val_pred)\n",
    "plot_confusion_matrix(y_val, y_val_pred, \"decision_tree_downsampled_conf_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42, class_weight=\"balanced\")\n",
    "param_grid = dict(max_depth=list(range(1, 40)))\n",
    "\n",
    "best_params = get_best_estimator_params(rf, param_grid, X,Y)\n",
    "\n",
    "rf = RandomForestClassifier(max_depth = best_params['max_depth'], random_state=42,  class_weight=\"balanced\")\n",
    "rf.fit(X, Y)\n",
    "\n",
    "y_val_pred = rf.predict(X_val)\n",
    "\n",
    "scores(y_val, y_val_pred)\n",
    "plot_confusion_matrix(y_val, y_val_pred, \"Random Forest CM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalise Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_min_max, X_standard = normalize(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca_and_plot(X_train=X, y_train=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pca_and_plot(X_train=X_train_standard, y_train=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca_and_plot(X_train=X_train_min_max, y_train=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest neighbour classification on PCA data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knn, pca, principalComponents, principalComponentsTest, y_pred = get_best_pca_components(X_train=X_train_standard, y_train=y_train,\n",
    "                                       X_test=X_test_standard, y_test=y_test)\n",
    "scores(y_test, y_pred)\n",
    "plot_confusion_matrix(y_test, y_pred, \"knn_conf_matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda_result = lda.fit(X, Y).transform(X)\n",
    "y_pred = lda.predict(X_val)\n",
    "scores(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.manifold import Isomap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tsne = TSNE()\n",
    "tsne_result = tsne.fit_transform(X_train_standard,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "colors = ['navy', 'turquoise']\n",
    "for color, i, target_name in zip(colors, [0,1], [0,1]):\n",
    "    plt.scatter(tsne_result[y_train == i,0], tsne_result[y_train == i,1], alpha=.8, color=color,label=target_name)\n",
    "plt.legend(labels=[\"0\",\"1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "isomap = Isomap(10,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "isomap_result = isomap.fit_transform(X_train_standard)\n",
    "# isomap_result.dump(\"isomap_result.pickle\")\n",
    "# isomap_result = np.load(\"isomap_result.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "colors = ['navy', 'turquoise']\n",
    "for color, i, target_name in zip(colors, [0,1], [0,1]):\n",
    "    plt.scatter(isomap_result[y_train == i,0], isomap_result[y_train == i,1], alpha=.8, color=color,label=target_name)\n",
    "plt.legend(labels=[\"0\",\"1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train_standard, y_train)  \n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(recall_score(y_test, y_pred))\n",
    "print(precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(X_train_standard,y_train)\n",
    "y_pred = logisticRegr.predict(X_test_standard)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(recall_score(y_test, y_pred))\n",
    "print(precision_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
