{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from functools import reduce\n",
    "import pickle\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "# first_block = 400040\n",
    "# last_block = 400045\n",
    "\n",
    "with open('../pickles/ml/train_blocks', 'rb') as f:\n",
    "    block_list = pickle.load(f)\n",
    "\n",
    "#block_list = [400000]\n",
    "    \n",
    "#df = pd.read_pickle('../pickles/ranges/range/401180_to_401200.pickle')#.format(first_block,last_block))\n",
    "df = pd.read_pickle('../pickles/df/all_blocks.pickle')\n",
    "#df = pd.read_pickle('../pickles/df/400000.pickle')\n",
    "#df = pd.read_csv('./csv/400000addr.csv')\n",
    "#df[[col for col in df.columns if not 'Unnamed' in col]]\n",
    "\n",
    "# New columns for number of input and output transaction ids\n",
    "df['num_txo'] = df.groupby('id_t')['id_txo_out'].transform('nunique')\n",
    "df['num_txi'] = df.groupby('id_t')['id_txi'].transform('nunique')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class User:\n",
    "    def __init__(self, adrs, send_txs, rec_txs):\n",
    "        self.adr = set(adrs)\n",
    "        self.sending_tx = set(send_txs)\n",
    "        self.cadr = set()\n",
    "        if rec_txs is None:\n",
    "            self.receiving_tx = set()\n",
    "        else:\n",
    "            self.receiving_tx = set(rec_txs)\n",
    "        self.blocks = set()\n",
    "            \n",
    "def query_database(query):\n",
    "    # REMEMBER TO BE CONNECTED TO IMPERIAL WIFI!\n",
    "    graph_db = py2neo.Graph(\"https://dsi-bitcoin.doc.ic.ac.uk:7473/db/data/\", auth=(\"adi\", \"aditi123\"))\n",
    "    return graph_db.run(query)\n",
    "        \n",
    "#CHANGE LATER TO QUERY DATABASE INSTEAD\n",
    "def iadrs_from_tx(id_t):\n",
    "    return set(df['iadr'][df[\"id_t\"] == id_t])\n",
    "#     query_string = \"\"\"\n",
    "#     MATCH (t:Tx) <-[:IN]- (txi:TxIn) <-[:UNLOCK]- (a:Address) WHERE ID(t) = {}\n",
    "#     RETURN a.address as iadr\n",
    "#     \"\"\".format(id_t)\n",
    "#     x = query_database(query_string).to_data_frame()\n",
    "#     return set(x['iadr'])\n",
    "\n",
    "def oadrs_from_tx(id_t):\n",
    "    return set(df['oadr'][df[\"id_t\"] == id_t])\n",
    "#     query_string = \"\"\"\n",
    "#     MATCH (t:Tx) -[:OUT]-> (txo:TxOut) -[:LOCK]-> (a:Address) WHERE ID(t) = 113001822\n",
    "#     RETURN a.address as oadr\n",
    "#     \"\"\".format(id_t)\n",
    "#     x = query_database(query_string).to_data_frame()\n",
    "#     return set(x['oadr'])\n",
    "\n",
    "def tx_from_iadr(iadr):\n",
    "    return set(df['id_t'][df[\"iadr\"] == iadr])\n",
    "\n",
    "def block_from_tx(id_t):\n",
    "    return set(df['block_no'][df[\"id_t\"] == id_t])\n",
    "\n",
    "#FUNCTION TO WHICH YOU GIVE AN INPUT ADDRESS AND GET USER \n",
    "def get_user(input_adr):\n",
    "    to_inv = [input_adr]\n",
    "    user_iadrs = set()\n",
    "    seen_txs = set()\n",
    "    while to_inv:\n",
    "        current_iadr = to_inv.pop(0)\n",
    "        user_iadrs.add(current_iadr)\n",
    "        for id_t in tx_from_iadr(current_iadr):\n",
    "\n",
    "            if id_t not in seen_txs:\n",
    "                \n",
    "                seen_txs.add(id_t)\n",
    "                iadrs = iadrs_from_tx(id_t)\n",
    "                to_inv += iadrs.difference(user_iadrs) #Adding addr\n",
    "                user_iadrs.update(iadrs)\n",
    "            \n",
    "    return User(user_iadrs, seen_txs, None)\n",
    "\n",
    "#TAKES OUTPUT ADDRESS AND GIVES USER THAT HAS THAT ADDRESS AS INPUT\n",
    "def user_from_oadr(oadr):\n",
    "    for i,user in enumerate(users):\n",
    "        if oadr in user.adr:\n",
    "            return i        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heuristic 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make miner users\n",
      "make other users\n",
      "Which users have transacted with each other\n",
      "Total time to process 1: 612.5596525669098\n"
     ]
    }
   ],
   "source": [
    "#LIST OF LISTS OF USER AND THEIR ASSOCIATED ADDRESSES\n",
    "users = []\n",
    "\n",
    "starttime = time.time()        \n",
    "        \n",
    "# Bitcoin- \n",
    "bitcoin = User({str(0)}, set(), set()) #Make user object with bitcoin iadr (which is 0)\n",
    "seen_miner_iadrs_tx = defaultdict(set) #Make dict associating miner payment address with tx_ids they've been involved in\n",
    "\n",
    "for index, row in df[df['iadr'] == str(0)].iterrows(): #Going through all mining txs\n",
    "    bitcoin.sending_tx.add(row['id_t']) #Adding tx id to bitcoin user's txs\n",
    "    seen_miner_iadrs_tx[row['oadr']].add(row['id_t']) # Updating dict to register the tx_id as corresponding to miners adr. If new, then new key added, otherwise added to values of existing key\n",
    "\n",
    "users.append(bitcoin) # Add bitcoin user\n",
    "already_seen_adr = {'0'}  # Bitcoin iadr has already been seen\n",
    "\n",
    "print(\"make miner users\")\n",
    "# make miners users\n",
    "for adr, id_ts in seen_miner_iadrs_tx.items(): #Go through dictionary for every adr (miner) and txs he's been involved\n",
    "    if adr not in already_seen_adr:\n",
    "        miner = get_user(adr) #From an address, give back user ... aka identify all addresses belonging to miner\n",
    "        miner.adr.add(adr) #Make sure adrs and txs are added in\n",
    "        miner.receiving_tx.update(id_ts)\n",
    "        users.append(miner)\n",
    "        already_seen_adr.update(miner.adr)#Made sure miner's addresses are in already seen so that we don't create a second user with the same addresses\n",
    "\n",
    "print(\"make other users\")\n",
    "## ASSOCIATE INPUT ADDRESS AND TX WITH EACH USER IN BLOCK\n",
    "# make other users from heuristic\n",
    "for input_adr in df.iadr:\n",
    "    if input_adr not in already_seen_adr:\n",
    "        user = get_user(input_adr)\n",
    "        users.append(user)\n",
    "        already_seen_adr.update(user.adr)\n",
    "        \n",
    "edges = defaultdict(int)\n",
    "\n",
    "print(\"Which users have transacted with each other\")\n",
    "#WHICH USERS IN HAVE TRANSACTED WITH EACH OTHER\n",
    "for i,user in enumerate(users):\n",
    "    for tx_id in user.sending_tx:\n",
    "        for oadr in oadrs_from_tx(tx_id):\n",
    "            if oadr in already_seen_adr:\n",
    "                    edges[(i, user_from_oadr(oadr))]+=1  \n",
    "                    \n",
    "print(\"Total time to process 1:\", time.time()-starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16750"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heuristic 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400040\n",
      "400041\n",
      "400042\n",
      "400043\n",
      "400044\n",
      "400045\n",
      "Total time to process 2: 4.160162448883057\n"
     ]
    }
   ],
   "source": [
    "starttime = time.time()     \n",
    "\n",
    "otc_dic = {}\n",
    "#for block in block_list:\n",
    "for block in range(first_block,last_block+1,1):\n",
    "    if(os.path.exists(\"../pickles/df/{}.pickle\".format(block)) and os.path.exists(\"../pickles/otc/otc_{}.pickle\".format(block))):\n",
    "        print(block)\n",
    "        with open ('../pickles/otc/otc_{}.pickle'.format(block), 'rb') as fp:\n",
    "            otc_dic[block] = pickle.load(fp)\n",
    "    \n",
    "not_seen = list(reduce(set.symmetric_difference, (set(val) for val in otc_dic.values())))\n",
    "appeared_once_o= list(df.drop_duplicates(['id_txo_out']).oadr.value_counts()[df.drop_duplicates(['id_txo_out']).oadr.value_counts()==1].index)\n",
    "all_iadrs= list(df.iadr.value_counts().index)\n",
    "o_never_used_as_i = set(appeared_once_o).difference(all_iadrs)\n",
    "coin_gen_adr = list(df[df['iadr'] == str(0)].drop_duplicates(['oadr']).oadr)\n",
    "\n",
    "possible_otc = o_never_used_as_i.intersection(set(not_seen)).difference(set(coin_gen_adr))\n",
    "\n",
    "#Change Transactions\n",
    "for i,user in enumerate(users):\n",
    "    cadrs_for_user = set()\n",
    "    for tx_id in user.sending_tx:    #CHECK THIS\n",
    "        o = oadrs_from_tx(tx_id)\n",
    "        potential_cadr = []\n",
    "        for oadr in o:\n",
    "            if oadr in possible_otc and oadr not in iadrs_from_tx(tx_id):#not in user.adr:\n",
    "                potential_cadr.append(oadr)\n",
    "        if len(potential_cadr)==1:\n",
    "            cadrs_for_user.add(potential_cadr[0])\n",
    "            #not_seen.remove(potential_cadr[0]) #Ensure that same change address won't be another user\n",
    "    user.adr.update(cadrs_for_user)   \n",
    "    user.cadr.update(cadrs_for_user) \n",
    "\n",
    "print(\"Total time to process 2:\", time.time()-starttime)\n",
    "\n",
    "#Save Users found\n",
    "#with open('../pickles/users/users_{}_to_{}.pickle'.format(first_block,last_block),'wb') as f:\n",
    "with open('../pickles/pool/all_users.pickle','wb') as f:    \n",
    "    pickle.dump(users,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5191\n"
     ]
    }
   ],
   "source": [
    "def getCouples(users):\n",
    "    to_combine = []\n",
    "    for i, user in enumerate(users):\n",
    "        for k, otheruser in enumerate(users):\n",
    "            if user.adr.intersection(otheruser.adr) and i!=k:\n",
    "                to_combine.append((i,k))\n",
    "    return to_combine\n",
    "\n",
    "print(len(users))\n",
    "to_combine = getCouples(users) \n",
    "while to_combine:\n",
    "    print(\"to_combine length \", len(to_combine))\n",
    "    st = set(users)\n",
    "    for tple in to_combine:\n",
    "        user1 = users[tple[0]]\n",
    "        user2 = users[tple[1]]\n",
    "        if user1 in st and user2 in st:\n",
    "            #print(tple)\n",
    "            st.remove(user1)\n",
    "            st.remove(user2)\n",
    "            user1.adr = user1.adr.union(user2.adr)\n",
    "            st.add(user1)\n",
    "    users = list(st)\n",
    "    print(len(users))\n",
    "    to_combine = getCouples(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in users:\n",
    "    blx = set()\n",
    "    for tx in user.sending_tx:\n",
    "        blx.update(block_from_tx(tx))\n",
    "    for tx in user.receiving_tx:\n",
    "        blx.update(block_from_tx(tx))\n",
    "    user.blocks.update(blx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No repeats txid\n",
      "No repeats ads\n",
      "No repeats cads\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "tx_ids = []\n",
    "for user in users[1:]:#Drop out bitcoin user\n",
    "    tx_ids += list(user.sending_tx)\n",
    "\n",
    "#tx_ids = list.append([list(user.sending_tx) for user in users])\n",
    "        \n",
    "ads = []\n",
    "for i,user in enumerate(users):\n",
    "    for ad in user.adr:\n",
    "        ads.append(ad)\n",
    "\n",
    "cads = []\n",
    "for i,user in enumerate(users):\n",
    "    for ad in user.cadr:\n",
    "        cads.append(ad)\n",
    "        \n",
    "# cads = []\n",
    "# for i,user in enumerate(users):\n",
    "#     for cad in user.cadr:\n",
    "#         cads.append(cad)\n",
    "\n",
    "if Counter(tx_ids).most_common(10)[0][1] == 1:  ##Repeated txids between bitcoin and the miners\n",
    "    print(\"No repeats txid\")\n",
    "    \n",
    "if Counter(ads).most_common(10)[0][1] == 1:\n",
    "    print(\"No repeats ads\")\n",
    "\n",
    "if Counter(cads).most_common(10)[0][1] == 1:\n",
    "    print(\"No repeats cads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Read Users found\n",
    "# with open('../pickles/users/users_{}_to_{}.pickle'.format(first_block,last_block), 'rb') as f:\n",
    "#     users = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.groupby('id_t').agg({'oadr':['nunique', 'count'],'iadr':['nunique', 'count'],'id_txo_in':['nunique', 'count'],'id_txo_out':['nunique', 'count']})\n",
    "#df.to_csv('users.csv', columns=['input_user','output_user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactions between users (constructing user graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time to construct user graph: 102.31555366516113\n"
     ]
    }
   ],
   "source": [
    "#Construct User Graph\n",
    "df['input_user'] = df['iadr']  \n",
    "df['output_user'] = df['oadr']\n",
    "\n",
    "starttime = time.time() \n",
    "#Replacing all input addresses and output addresses with a user corresponding to that address\n",
    "for i, user in enumerate(users): \n",
    "    #assert(isinstance(i, int))\n",
    "    df['input_user'] = df['input_user'].apply(lambda x: i if x in user.adr else x)\n",
    "    df['output_user'] = df['output_user'].apply(lambda x: i if x in user.adr else x)\n",
    "    \n",
    "for tx_id, output_user in df[['id_t','output_user']].values:\n",
    "    if isinstance(output_user,int):\n",
    "        users[output_user].receiving_tx.add(tx_id)\n",
    "print(\"Total time to construct user graph:\", time.time()-starttime)\n",
    "\n",
    "#df.to_pickle(\"../pickles/df/{}_to_{}_users.pickle\".format(first_block,last_block))\n",
    "df.to_pickle(\"../pickles/pool/all_df_with_users.pickle\")\n",
    "#Save Users found\n",
    "#with open('../pickles/users/users_{}_to_{}.pickle'.format(first_block,last_block),'wb') as f:\n",
    "with open('../pickles/pool/all_users.pickle','wb') as f: \n",
    "    pickle.dump(users,f)\n",
    "    \n",
    "# can't trust input_val column now\n",
    "# because dropped lots of inputs\n",
    "edges_df0 = df.drop_duplicates(['input_user', 'id_txo_out'])\n",
    "edges_df = edges_df0.groupby(['input_user', 'output_user']).apply(lambda group: group['output_val'].sum()).reset_index()\n",
    "#edges_df0 = edges_df0.rename(columns={0: 'edge_amount'})\n",
    "\n",
    "tups = [(input_user, output_user, amount) for (index, input_user, output_user, amount) in edges_df.itertuples()]\n",
    "\n",
    "#with open(\"../pickles/user_graphs/{}_to_{}_users.pickle\".format(first_block,last_block), 'wb') as f:\n",
    "with open('../pickles/pool/all_users_graph.pickle','wb') as f: \n",
    "    pickle.dump(tups,f)\n",
    "#tups2 = [(input_user, output_user, amount) for (index, input_user, output_user, amount) in edges_df2.itertuples()]\n",
    "\n",
    "# assert(all(tups == tups2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()\n",
    "# df['iadr'].apply(type).value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
